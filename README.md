# ğŸš€ Projet Big Data - Traitement DistribuÃ© UCAO

[![Docker](https://img.shields.io/badge/Docker-20.10+-blue.svg)](https://docker.com)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3.4-yellow.svg)](https://hadoop.apache.org)
[![Spark](https://img.shields.io/badge/Spark-3.4.0-orange.svg)](https://spark.apache.org)
[![MongoDB](https://img.shields.io/badge/MongoDB-6.0-green.svg)](https://mongodb.com)
[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)

**Projet de Master 1 - UniversitÃ© Catholique de l'Afrique de l'Ouest (UCAO)**  
**AnnÃ©e acadÃ©mique:** 2024-2025  
**Module:** Traitement DistribuÃ©  

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du Projet](#structure-du-projet)
- [Analyses Disponibles](#analyses-disponibles)
- [Monitoring](#monitoring)
- [DÃ©monstration VidÃ©o](#dÃ©monstration-vidÃ©o)
- [Technologies UtilisÃ©es](#technologies-utilisÃ©es)
- [Auteur](#auteur)

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente une **solution Big Data complÃ¨te** pour une entreprise confrontÃ©e Ã  l'explosion de ses donnÃ©es. La solution comprend:

- **Cluster Hadoop distribuÃ©** (1 master, 1 secondary, 3 workers)
- **Traitement Spark** pour analyses avancÃ©es
- **IntÃ©gration MongoDB** pour donnÃ©es temps rÃ©el
- **Analyses Apache Pig** pour exploration de donnÃ©es
- **Application web interactive** avec dashboard temps rÃ©el
- **Architecture 100% containerisÃ©e** avec Docker

### ğŸ¯ Objectifs RÃ©alisÃ©s

âœ… **Environnement Hadoop/Spark** avec haute disponibilitÃ©  
âœ… **Analyse exploratoire** avec Apache Pig  
âœ… **Connecteur MongoDB-Hadoop** natif  
âœ… **Application dynamique** avec visualisations temps rÃ©el  
âœ… **Workflow documentÃ©** et automatisÃ©  
âœ… **PrÃ©sentation vidÃ©o** complÃ¨te  

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    subgraph "Docker Network: bigdata-network"
        subgraph "Hadoop Cluster"
            MASTER[ğŸ–¥ï¸ Master Node<br/>NameNode + ResourceManager<br/>Spark Master]
            SECONDARY[ğŸ”„ Secondary Master<br/>Secondary NameNode]
            W1[ğŸ’¾ Worker 1<br/>DataNode + NodeManager<br/>Spark Worker]
            W2[ğŸ’¾ Worker 2<br/>DataNode + NodeManager<br/>Spark Worker]
            W3[ğŸ’¾ Worker 3<br/>DataNode + NodeManager<br/>Spark Worker]
        end
        
        MONGO[ğŸƒ MongoDB<br/>DonnÃ©es Temps RÃ©el]
        WEBAPP[ğŸŒ Application Web<br/>Flask + Dash]
        
        MASTER --> W1
        MASTER --> W2
        MASTER --> W3
        SECONDARY --> MASTER
        WEBAPP --> MASTER
        WEBAPP --> MONGO
    end
```

### ğŸ“Š Ports ExposÃ©s

| Service | Port | Description |
|---------|------|-------------|
| **Application Web** | 5000 | Interface principale |
| **Dashboard** | 8050 | Visualisations interactives |
| **NameNode UI** | 9870 | Interface Hadoop |
| **ResourceManager** | 8088 | Interface YARN |
| **Spark Master** | 8080 | Interface Spark |
| **Secondary NameNode** | 9868 | Interface Secondary |
| **MongoDB** | 27017 | Base de donnÃ©es |

## ğŸ› ï¸ PrÃ©requis

### SystÃ¨me
- **OS:** Linux (Ubuntu 20.04+), macOS (10.15+), Windows 10+
- **RAM:** 8GB minimum, 16GB recommandÃ©s
- **Stockage:** 10GB d'espace libre
- **RÃ©seau:** AccÃ¨s internet pour tÃ©lÃ©chargements

### Logiciels
- [Docker](https://docs.docker.com/get-docker/) 20.10+
- [Docker Compose](https://docs.docker.com/compose/install/) 1.29+
- Git (pour cloner le projet)
- Navigateur web moderne

## ğŸš€ Installation

### Installation Automatique (RecommandÃ©e)

```bash
# 1. TÃ©lÃ©charger et exÃ©cuter le script d'installation
curl -fsSL https://raw.githubusercontent.com/[votre-repo]/install.sh | bash

# OU tÃ©lÃ©charger manuellement
wget https://raw.githubusercontent.com/[votre-repo]/install.sh
chmod +x install.sh
./install.sh
```

### Installation Manuelle

```bash
# 1. Cloner le projet
git clone https://github.com/[votre-repo]/bigdata-ucao.git
cd bigdata-ucao

# 2. Rendre les scripts exÃ©cutables
chmod +x scripts/*.sh

# 3. DÃ©marrer le cluster
./scripts/start-cluster.sh
```

### VÃ©rification de l'Installation

```bash
# VÃ©rifier tous les services
./scripts/monitor-cluster.sh

# VÃ©rifier les conteneurs
docker ps
```

## ğŸ’¡ Utilisation

### DÃ©marrage Rapide

```bash
# DÃ©marrer le cluster complet
./scripts/start-cluster.sh

# Attendre ~3 minutes pour le dÃ©marrage complet
# AccÃ©der Ã  l'application: http://localhost:5000
```

### ExÃ©cution des Analyses

```bash
# 1. Analyse exploratoire avec Apache Pig
./scripts/run-pig-analysis.sh

# 2. Lecture et traitement MongoDB avec Spark  
./scripts/run-mongodb-analysis.sh

# 3. Tests complets Spark
./scripts/run-spark-tests.sh
```

### ArrÃªt du SystÃ¨me

```bash
# ArrÃªt propre de tous les services
docker-compose down -v
```

## ğŸ“ Structure du Projet

```
bigdata-ucao/
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ ğŸ“„ README.md                   # Documentation principale
â”œâ”€â”€ ğŸ“ hadoop-master/              # Configuration nÅ“ud master
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile
â”‚   â”œâ”€â”€ ğŸ“ config/                 # Config Hadoop
â”‚   â”œâ”€â”€ ğŸ“ spark-config/           # Config Spark
â”‚   â””â”€â”€ ğŸ“œ start-master.sh
â”œâ”€â”€ ğŸ“ hadoop-secondary/           # Configuration secondary master
â”œâ”€â”€ ğŸ“ hadoop-worker/              # Configuration workers
â”œâ”€â”€ ğŸ“ webapp/                     # Application web
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile
â”‚   â”œâ”€â”€ ğŸ app.py                  # Application Flask/Dash
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
â”‚   â””â”€â”€ ğŸ“ templates/
â”œâ”€â”€ ğŸ“ pig-scripts/                # Scripts d'analyse Pig
â”‚   â”œâ”€â”€ ğŸ“œ load_and_explore.pig
â”‚   â””â”€â”€ ğŸ“œ advanced_analysis.pig
â”œâ”€â”€ ğŸ“ hadoop-scripts/             # Scripts Spark/Python
â”‚   â”œâ”€â”€ ğŸ mongodb_reader.py
â”‚   â””â”€â”€ ğŸ spark_tests.py
â”œâ”€â”€ ğŸ“ scripts/                    # Scripts d'automatisation
â”‚   â”œâ”€â”€ ğŸ“œ start-cluster.sh
â”‚   â”œâ”€â”€ ğŸ“œ monitor-cluster.sh
â”‚   â”œâ”€â”€ ğŸ“œ run-pig-analysis.sh
â”‚   â””â”€â”€ ğŸ“œ run-mongodb-analysis.sh
â”œâ”€â”€ ğŸ“ data/                       # DonnÃ©es de test
â”‚   â””â”€â”€ ğŸ“Š sales_data.csv
â””â”€â”€ ğŸ“ mongodb-init/               # Initialisation MongoDB
    â””â”€â”€ ğŸƒ init.js
```

## ğŸ“ˆ Analyses Disponibles

### 1. Analyses Apache Pig

**Script:** `pig-scripts/load_and_explore.pig`

- ğŸ“Š **Ventes par catÃ©gorie** - AgrÃ©gations et comptages
- ğŸ† **Top 5 produits** - Classement par quantitÃ© vendue  
- ğŸ—ºï¸ **Analyse rÃ©gionale** - Revenus par rÃ©gion
- ğŸ’° **Ventes importantes** - Filtrage des transactions > 1000$

**ExÃ©cution:**
```bash
./scripts/run-pig-analysis.sh
```

### 2. IntÃ©gration MongoDB-Spark

**Script:** `hadoop-scripts/mongodb_reader.py`

- ğŸ”— **Lecture MongoDB** via Spark Connector
- ğŸ¤ **Jointures** collections MongoDB + donnÃ©es HDFS
- ğŸ“Š **Analyses combinÃ©es** temps rÃ©el + historique
- ğŸ’¾ **Sauvegarde HDFS** des rÃ©sultats

**ExÃ©cution:**
```bash
./scripts/run-mongodb-analysis.sh
```

### 3. Application Web Interactive

**URL:** http://localhost:5000

#### FonctionnalitÃ©s:
- ğŸ“Š **Dashboard temps rÃ©el** avec mÃ©triques KPI
- ğŸ“ˆ **Graphiques interactifs** (camembert, courbes, barres)
- ğŸ“± **Interface responsive** Bootstrap
- ğŸ”„ **Actualisation automatique** (5s)
- ğŸ›ï¸ **Monitoring services** Hadoop/Spark

#### Visualisations:
- RÃ©partition des ventes par catÃ©gorie
- Ã‰volution temporelle des revenus
- Analyse gÃ©ographique par rÃ©gion
- Ventes temps rÃ©el par heure
- Tableau des transactions rÃ©centes

## ğŸ–¥ï¸ Monitoring

### Interface Web de Monitoring

```bash
# AccÃ¨s aux interfaces d'administration
open http://localhost:9870  # Hadoop NameNode
open http://localhost:8088  # YARN ResourceManager  
open http://localhost:8080  # Spark Master
```

### Monitoring en Ligne de Commande

```bash
# Ã‰tat complet du cluster
./scripts/monitor-cluster.sh

# Logs des conteneurs
docker logs hadoop-master
docker logs webapp

# Statistiques HDFS
docker exec hadoop-master hdfs dfsadmin -report

# Applications YARN
docker exec hadoop-master yarn application -list
```

### MÃ©triques SurveillÃ©es

- âœ… **Ã‰tat des conteneurs** Docker
- âœ… **SantÃ© des services** Hadoop/Spark/MongoDB
- âœ… **Utilisation HDFS** (espace, rÃ©plication)
- âœ… **Applications actives** YARN/Spark
- âœ… **ConnectivitÃ© rÃ©seau** entre nÅ“uds

## ğŸ¬ DÃ©monstration VidÃ©o

### Script de PrÃ©sentation

La vidÃ©o de dÃ©monstration (15-20 min) couvre:

1. **Introduction** - Contexte et objectifs (2 min)
2. **Architecture** - Vue d'ensemble technique (3 min)
3. **DÃ©ploiement** - DÃ©marrage automatisÃ© (4 min)
4. **Analyses Pig** - Exploration de donnÃ©es (4 min)
5. **MongoDB-Hadoop** - IntÃ©gration temps rÃ©el (3 min)
6. **Application Web** - Dashboard interactif (4 min)
7. **Monitoring** - Tests et surveillance (2 min)
8. **Conclusions** - RÃ©capitulatif et perspectives (2 min)

### Points ClÃ©s DÃ©montrÃ©s

- âœ… DÃ©marrage complet en < 3 minutes
- âœ… Analyses Pig produisant des insights business
- âœ… IntÃ©gration MongoDB-Hadoop fonctionnelle
- âœ… Dashboard temps rÃ©el auto-actualisÃ©
- âœ… Monitoring complet de l'infrastructure

## ğŸ› ï¸ Technologies UtilisÃ©es

### Infrastructure
- **ğŸ³ Docker & Docker Compose** - Containerisation
- **ğŸ”§ Apache Hadoop 3.3.4** - SystÃ¨me de fichiers distribuÃ©
- **âš¡ Apache Spark 3.4.0** - Moteur de traitement
- **ğŸ· Apache Pig 0.17.0** - Analyse exploratoire
- **ğŸƒ MongoDB 6.0** - Base NoSQL temps rÃ©el

### DÃ©veloppement
- **ğŸ Python 3.9** - Langage principal
- **ğŸŒ¶ï¸ Flask 2.3** - Framework web backend
- **ğŸ“Š Dash 2.11** - Framework de visualisation
- **ğŸ“ˆ Plotly 5.15** - Graphiques interactifs
- **ğŸ¨ Bootstrap 5.1** - Interface utilisateur

### Outils
- **ğŸ“œ Shell Scripts** - Automatisation
- **ğŸ” Monitoring** - Scripts de surveillance
- **ğŸ§ª Testing** - Suite de tests automatisÃ©s

## ğŸ‘¨â€ğŸ’» Auteur

**Ã‰tudiant Master 1 UCAO**  
**AnnÃ©e:** 2024-2025  
**Module:** Traitement DistribuÃ©  
**Date de rendu:** 29 aoÃ»t 2025  

---

## ğŸ“ Licence

Ce projet est dÃ©veloppÃ© dans le cadre acadÃ©mique du Master 1 UCAO 2024-2025.

## ğŸ†˜ Support

En cas de problÃ¨me:

1. VÃ©rifier les [prÃ©requis](#prÃ©requis)
2. Consulter les logs: `docker logs [container-name]`  
3. ExÃ©cuter le monitoring: `./scripts/monitor-cluster.sh`
4. RedÃ©marrer si nÃ©cessaire: `docker-compose restart`

---

> **Note:** Ce projet dÃ©montre une maÃ®trise complÃ¨te des technologies Big Data modernes dans un environnement de production simulÃ©. L'architecture proposÃ©e est scalable et peut Ãªtre adaptÃ©e pour des cas d'usage rÃ©els en entreprise.